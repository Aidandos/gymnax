{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving Pendulum Controllers\n",
    "### [Last Update: July 2022][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/gymnax/blob/main/examples/es_in_gymnax.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "!pip install -q git+https://github.com/RobertTLange/gymnax.git@main\n",
    "!pip install -q git+https://github.com/RobertTLange/evosax.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Rollouts with `gymnax` Environments\n",
    "\n",
    "In this notebook we will use `gymnax` to parallelize fitness rollouts across population members and initial conditions. Let's start by defining a policy and the corresponding episode rollout using the `RolloutWrapper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500,), DeviceArray([-500.], dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from evosax import NetworkMapper\n",
    "\n",
    "# MLP Policy with gaussian readout for pendulum\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model = NetworkMapper[\"MLP\"](\n",
    "    num_hidden_units=64,\n",
    "    num_hidden_layers=2,\n",
    "    num_output_units=3,\n",
    "    hidden_activation=\"relu\",\n",
    "    output_activation=\"categorical\",\n",
    ")\n",
    "\n",
    "import gymnax\n",
    "\n",
    "env, env_params = gymnax.make(\"Acrobot-v1\")\n",
    "pholder = jnp.zeros(env.observation_space(env_params).shape)\n",
    "policy_params = model.init(\n",
    "    rng,\n",
    "    x=pholder,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "\n",
    "from gymnax.experimental import RolloutWrapper\n",
    "\n",
    "# Define rollout manager for pendulum env\n",
    "manager = RolloutWrapper(model.apply, env_name=\"Acrobot-v1\")\n",
    "\n",
    "# Simple single episode rollout for policy\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.single_rollout(rng, policy_params)\n",
    "reward.shape, cum_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-ES with MLP Controller\n",
    "\n",
    "Next we instantiate the Evolution Strategy and get a set of parameters to evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterReshaper: 4803 parameters detected for optimization.\n"
     ]
    }
   ],
   "source": [
    "from evosax import OpenES\n",
    "from evosax import ParameterReshaper, FitnessShaper, NetworkMapper\n",
    "\n",
    "# Helper for parameter reshaping\n",
    "param_reshaper = ParameterReshaper(policy_params)\n",
    "\n",
    "# Instantiate and initialize the evolution strategy\n",
    "strategy = OpenES(popsize=100,\n",
    "                  num_dims=param_reshaper.total_params,\n",
    "                  opt_name=\"adam\")\n",
    "\n",
    "es_params = strategy.default_params\n",
    "es_params = es_params.replace(sigma_init=0.1, sigma_decay=0.999, sigma_limit=0.01)\n",
    "es_params = es_params.replace(opt_params=es_params.opt_params.replace(\n",
    "    lrate_init=0.1, lrate_decay=0.999, lrate_limit=0.001))\n",
    "\n",
    "es_state = strategy.initialize(rng)\n",
    "\n",
    "fit_shaper = FitnessShaper(maximize=True, centered_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  0 Generation:  -496.91\n",
      "Generation:  20 Generation:  -488.30875\n",
      "Generation:  40 Generation:  -265.81\n",
      "Generation:  60 Generation:  -102.61312\n",
      "Generation:  80 Generation:  -83.508125\n",
      "Generation:  100 Generation:  -82.125\n",
      "Generation:  120 Generation:  -79.756874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y4/1lwbxdz55wzg_83326j5cjk40000gn/T/ipykernel_43774/1110817818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreshaped_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrng_batch_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_mc_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_batch_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcum_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfit_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_shaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_generations = 100\n",
    "num_mc_evals = 16\n",
    "print_every_k_gens = 20\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    rng, rng_init, rng_ask, rng_eval = jax.random.split(rng, 4)\n",
    "    x, es_state = strategy.ask(rng_ask, es_state)\n",
    "    reshaped_params = param_reshaper.reshape(x)\n",
    "    rng_batch_eval = jax.random.split(rng_eval, num_mc_evals)\n",
    "    _, _, _, _, _, cum_ret = manager.population_rollout(rng_batch_eval, reshaped_params)\n",
    "    fitness = cum_ret.mean(axis=1).squeeze()\n",
    "    fit_re = fit_shaper.apply(x, fitness)\n",
    "    es_state = strategy.tell(x, fit_re, es_state)\n",
    "    \n",
    "    if gen % print_every_k_gens == 0:\n",
    "        print(\"Generation: \", gen, \"Generation: \", fitness.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`evosax` also already comes equipped with a fitness rollout wrapper for all `gymnax` environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax.problems import GymFitness\n",
    "\n",
    "evaluator = GymFitness(\"CartPole-v1\", num_env_steps=500, num_rollouts=16)\n",
    "evaluator.set_apply_fn(param_reshaper.vmap_dict, network.apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolving a Meta-LSTM to Control Different Length 2-Link Pendula\n",
    "\n",
    "By default the two links in the Acrobot task have length 1. Wouldn't it be cool if we could solve the task for many different lengths? We will now evolve a recurrent controller that is capable of solving the Acrobot swing up task for all link lengths that sum up to two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvParams(dt=0.2, link_length_1=1.0, link_length_2=1.0, link_mass_1=1.0, link_mass_2=1.0, link_com_pos_1=0.5, link_com_pos_2=0.5, link_moi=1.0, max_vel_1=12.566370614359172, max_vel_2=28.274333882308138, available_torque=DeviceArray([-1.,  0.,  1.], dtype=float32), torque_noise_max=0.0, max_steps_in_episode=500)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetworkMapper[\"LSTM\"](\n",
    "    num_hidden_units=32,\n",
    "    num_output_units=3,\n",
    "    output_activation=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvParams(dt=0.2, link_length_1=DeviceArray(1.0257741, dtype=float32), link_length_2=DeviceArray(0.9742259, dtype=float32), link_mass_1=1.0, link_mass_2=1.0, link_com_pos_1=0.5, link_com_pos_2=0.5, link_moi=1.0, max_vel_1=12.566370614359172, max_vel_2=28.274333882308138, available_torque=DeviceArray([-1.,  0.,  1.], dtype=float32), torque_noise_max=0.0, max_steps_in_episode=500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gymnax.environments.classic_control.acrobot import EnvParams\n",
    "\n",
    "# Sample a batch of environment parameters\n",
    "def sample_link_params(rng, min_link=0.1, max_link=1.9):\n",
    "    link_length_1 = jax.random.uniform(rng, (), minval=min_link, maxval=max_link)\n",
    "    link_length_2 = 2 - link_length_1\n",
    "    return EnvParams(link_length_1=link_length_1, link_length_2=link_length_2)\n",
    "\n",
    "env_params = sample_link_params(rng)\n",
    "env_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(rng_input, policy_params, steps_in_episode):\n",
    "  \"\"\"Rollout a jitted gymnax episode with lax.scan.\"\"\"\n",
    "  # Reset the environment\n",
    "  rng_reset, rng_episode, rng_link = jax.random.split(rng_input, 3)\n",
    "  env_params = sample_link_params(rng_link)\n",
    "  obs, state = env.reset(rng_reset, env_params)\n",
    "  hidden = model.initialize_carry()\n",
    "\n",
    "  def policy_step(state_input, tmp):\n",
    "      \"\"\"lax.scan compatible step transition in jax env.\"\"\"\n",
    "      obs, state, policy_params, rng, prev_a, hidden, cum_reward, valid_mask = state_input\n",
    "      rng, rng_step, rng_net = jax.random.split(rng, 3)\n",
    "      one_hot_action = jax.nn.one_hot(prev_a, 3).squeeze()\n",
    "      aug_in = jnp.hstack([obs, one_hot_action])\n",
    "      hidden, action = model.apply(policy_params, aug_in, hidden, rng_net)\n",
    "      next_obs, next_state, reward, done, _ = env.step(\n",
    "          rng_step, state, action, env_params\n",
    "      )\n",
    "      new_cum_reward = cum_reward + reward * valid_mask\n",
    "      new_valid_mask = valid_mask * (1 - done)\n",
    "      carry = [next_obs, next_state, policy_params, rng,\n",
    "               action, hidden, new_cum_reward, new_valid_mask]\n",
    "      return carry, [obs, action, reward, next_obs, done]\n",
    "\n",
    "  # Scan over episode step loop\n",
    "  carry_out, scan_out = jax.lax.scan(\n",
    "      policy_step,\n",
    "      [obs, state, policy_params, rng_episode, 0,\n",
    "      hidden, jnp.array([0.0]), jnp.array([1.0])],\n",
    "      (),\n",
    "      steps_in_episode\n",
    "  )\n",
    "  return carry_out[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([-500.], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pholder = jnp.zeros((9,))\n",
    "policy_params = model.init(\n",
    "    rng,\n",
    "    x=pholder,\n",
    "    rng=rng,\n",
    "    carry=model.initialize_carry()\n",
    ")\n",
    "\n",
    "rollout(rng, policy_params, steps_in_episode=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_rollout = jax.vmap(rollout, in_axes=(0, None, None))\n",
    "pop_rollout = jax.vmap(rng_rollout, in_axes=(None, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterReshaper: 5475 parameters detected for optimization.\n"
     ]
    }
   ],
   "source": [
    "# Helper for parameter reshaping\n",
    "param_reshaper = ParameterReshaper(policy_params)\n",
    "\n",
    "# Instantiate and initialize the evolution strategy\n",
    "strategy = OpenES(popsize=100,\n",
    "                  num_dims=param_reshaper.total_params,\n",
    "                  opt_name=\"adam\")\n",
    "\n",
    "es_params = strategy.default_params\n",
    "es_params = es_params.replace(sigma_init=0.1, sigma_decay=0.999, sigma_limit=0.01)\n",
    "es_params = es_params.replace(opt_params=es_params.opt_params.replace(\n",
    "    lrate_init=0.1, lrate_decay=0.999, lrate_limit=0.001))\n",
    "\n",
    "es_state = strategy.initialize(rng)\n",
    "\n",
    "fit_shaper = FitnessShaper(maximize=True, centered_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  0 Generation:  -493.6856\n",
      "Generation:  20 Generation:  -449.6606\n",
      "Generation:  40 Generation:  -225.56062\n",
      "Generation:  60 Generation:  -139.83624\n"
     ]
    }
   ],
   "source": [
    "num_generations = 100\n",
    "num_mc_evals = 16\n",
    "print_every_k_gens = 20\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    rng, rng_init, rng_ask, rng_eval = jax.random.split(rng, 4)\n",
    "    x, es_state = strategy.ask(rng_ask, es_state)\n",
    "    reshaped_params = param_reshaper.reshape(x)\n",
    "    rng_batch_eval = jax.random.split(rng_eval, num_mc_evals)\n",
    "    cum_ret = pop_rollout(rng_batch_eval, reshaped_params, 500)\n",
    "    fitness = cum_ret.mean(axis=1).squeeze()\n",
    "    fit_re = fit_shaper.apply(x, fitness)\n",
    "    es_state = strategy.tell(x, fit_re, es_state)\n",
    "    \n",
    "    if gen % print_every_k_gens == 0:\n",
    "        print(\"Generation: \", gen, \"Generation: \", fitness.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-toolbox",
   "language": "python",
   "name": "mle-toolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
