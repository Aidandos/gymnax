{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `gymnax`: Classic Gym Environments in JAX\n",
    "### [Last Update: July 2022][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/gymnax/blob/main/examples/getting_started.ipynb)\n",
    "\n",
    "Welcome to `gymnax`, the one stop shop for fast classic Reinforcement Learning environments powered by JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "!pip install -q git+https://github.com/RobertTLange/gymnax.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic API: `gymnax.make()`, `env.reset()`, `env.step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " [CpuDevice(id=0),\n",
       "  CpuDevice(id=1),\n",
       "  CpuDevice(id=2),\n",
       "  CpuDevice(id=3),\n",
       "  CpuDevice(id=4),\n",
       "  CpuDevice(id=5),\n",
       "  CpuDevice(id=6),\n",
       "  CpuDevice(id=7)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the number of (emulated) host devices\n",
    "num_devices = 8\n",
    "os.environ['XLA_FLAGS'] = f\"--xla_force_host_platform_device_count={num_devices}\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import gymnax\n",
    "\n",
    "jax.device_count(), jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvParams(max_speed=8.0, max_torque=2.0, dt=0.05, g=10.0, m=1.0, l=1.0, max_steps_in_episode=200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, key_reset, key_policy, key_step = jax.random.split(rng, 4)\n",
    "\n",
    "# Create the Pendulum-v1 environment\n",
    "env, env_params = gymnax.make(\"Pendulum-v1\")\n",
    "\n",
    "# Inspect default environment settings\n",
    "env_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get an overview of all implemented environments as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CartPole-v1',\n",
       " 'Pendulum-v1',\n",
       " 'Acrobot-v1',\n",
       " 'MountainCar-v0',\n",
       " 'MountainCarContinuous-v0',\n",
       " 'Asterix-MinAtar',\n",
       " 'Breakout-MinAtar',\n",
       " 'Freeway-MinAtar',\n",
       " 'SpaceInvaders-MinAtar',\n",
       " 'Catch-bsuite',\n",
       " 'DeepSea-bsuite',\n",
       " 'MemoryChain-bsuite',\n",
       " 'UmbrellaChain-bsuite',\n",
       " 'DiscountingChain-bsuite',\n",
       " 'MNISTBandit-bsuite',\n",
       " 'SimpleBandit-bsuite',\n",
       " 'FourRooms-misc',\n",
       " 'MetaMaze-misc',\n",
       " 'PointRobot-misc',\n",
       " 'BernoulliBandit-misc',\n",
       " 'GaussianBandit-misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gymnax.registered_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([-0.939326  , -0.34302574, -0.6520283 ], dtype=float32),\n",
       " EnvState(theta=DeviceArray(-2.7914565, dtype=float32), theta_dot=DeviceArray(-0.6520283, dtype=float32), last_u=DeviceArray(0., dtype=float32, weak_type=True), time=DeviceArray(0, dtype=int32, weak_type=True)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, state = env.reset(key_reset, env_params)\n",
    "obs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DeviceArray([-0.9494436 , -0.31393763, -0.6159719 ], dtype=float32),\n",
       " EnvState(theta=DeviceArray(-2.8222551, dtype=float32), theta_dot=DeviceArray(-0.6159719, dtype=float32), last_u=DeviceArray(1.9555049, dtype=float32), time=DeviceArray(1, dtype=int32, weak_type=True)),\n",
       " DeviceArray([-7.8385677], dtype=float32),\n",
       " DeviceArray(False, dtype=bool, weak_type=True))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space(env_params).sample(key_policy)\n",
    "n_obs, n_state, reward, done, _ = env.step(key_step, state, action, env_params)\n",
    "n_obs, n_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simply use the environment with its default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, state = env.reset(key_reset)\n",
    "action = env.action_space().sample(key_policy)\n",
    "n_obs, n_state, reward, done, _ = env.step(key_step, state, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gymnax` provides fully functional environment dynamics that can leverage the full power of JAX's function transformations. E.g. one common RL use-case the parallel rollout of multiple workers. Using a `vmap` across random seeds (one per worker) allows us to implement such a parallelization on a single machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "vmap_reset = jax.vmap(env.reset, in_axes=(0, None))\n",
    "vmap_step = jax.vmap(env.step, in_axes=(0, 0, 0, None))\n",
    "\n",
    "num_envs = 4\n",
    "vmap_keys = jax.random.split(rng, num_envs)\n",
    "\n",
    "obs, state = vmap_reset(vmap_keys, env_params)\n",
    "n_obs, n_state, reward, done, _ = vmap_step(vmap_keys, state, jnp.zeros(num_envs), env_params)\n",
    "print(n_obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can also choose to `pmap` across rollout workers (\"actors\") across multiple devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n"
     ]
    }
   ],
   "source": [
    "pmap_reset = jax.pmap(env.reset, in_axes=(0, None))\n",
    "pmap_step = jax.vmap(env.step, in_axes=(0, 0, 0, None))\n",
    "\n",
    "\n",
    "pmap_keys = jax.random.split(rng, num_devices)\n",
    "obs, state = pmap_reset(pmap_keys, env_params)\n",
    "n_obs, n_state, reward, done, _ = pmap_step(pmap_keys, state, jnp.zeros(num_devices), env_params)\n",
    "print(n_obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above has executed each worker-specific environment transition on a separate device, but we can also chain `vmap` and `pmap` to execute multiple workers on a single device and at the same time across multiple devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "map_reset = jax.pmap(vmap_reset, in_axes=(0, None))\n",
    "map_step = jax.pmap(vmap_step, in_axes=(0, 0, 0, None))\n",
    "\n",
    "map_keys = jnp.tile(vmap_keys, (num_devices, 1, 1))\n",
    "obs, state = map_reset(map_keys, env_params)\n",
    "n_obs, n_state, reward, done, _ = map_step(map_keys, state, jnp.zeros((num_devices, num_envs)), env_params)\n",
    "print(n_obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now easily leverage massive accelerator parallelism to churn through millions/billions of environment transitions when training 'sentient' agents. Note that in the code snippet above we have executed 8 times the same 4 environment workers, since we tiled/repeated the same key across the device axis. In general `pmap`-ing will require you to pay special attention to the shapes of the arrays that come out your operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jitted Episode Rollouts via `lax.scan`\n",
    "\n",
    "Let's now walk through an example of using `gymnax` with one of the common neural network libraries to parametrize a simple policy: `flax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple ReLU MLP.\"\"\"\n",
    "\n",
    "    num_hidden_units: int\n",
    "    num_hidden_layers: int\n",
    "    num_output_units: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, rng):\n",
    "        for l in range(self.num_hidden_layers):\n",
    "            x = nn.Dense(features=self.num_hidden_units)(x)\n",
    "            x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.num_output_units)(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = MLP(48, 1, 1)\n",
    "policy_params = model.init(rng, jnp.zeros(3), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(rng_input, policy_params, env_params, steps_in_episode):\n",
    "  \"\"\"Rollout a jitted gymnax episode with lax.scan.\"\"\"\n",
    "  # Reset the environment\n",
    "  rng_reset, rng_episode = jax.random.split(rng_input)\n",
    "  obs, state = env.reset(rng_reset, env_params)\n",
    "\n",
    "  def policy_step(state_input, tmp):\n",
    "      \"\"\"lax.scan compatible step transition in jax env.\"\"\"\n",
    "      obs, state, policy_params, rng = state_input\n",
    "      rng, rng_step, rng_net = jax.random.split(rng, 3)\n",
    "      action = model.apply(policy_params, obs, rng_net)\n",
    "      next_obs, next_state, reward, done, _ = env.step(\n",
    "          rng_step, state, action, env_params\n",
    "      )\n",
    "      carry = [next_obs, next_state, policy_params, rng]\n",
    "      return carry, [obs, action, reward, next_obs, done]\n",
    "\n",
    "  # Scan over episode step loop\n",
    "  _, scan_out = jax.lax.scan(\n",
    "      policy_step,\n",
    "      [obs, state, policy_params, rng_episode],\n",
    "      (),\n",
    "      steps_in_episode\n",
    "  )\n",
    "  # Return masked sum of rewards accumulated by agent in episode\n",
    "  obs, action, reward, next_obs, done = scan_out\n",
    "  return obs, action, reward, next_obs, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 3), (200, 1), DeviceArray(-1621.5863, dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jit-Compiled Episode Rollout\n",
    "jit_rollout = jax.jit(rollout, static_argnums=3)\n",
    "obs, action, reward, next_obs, done = jit_rollout(rng, policy_params, env_params, 200)\n",
    "obs.shape, reward.shape, jnp.sum(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can wrap this `rollout` function with the magic of JAX and for all implemented RL environments. But we also provide a simple that does so for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n"
     ]
    }
   ],
   "source": [
    "from gymnax.experimental import RolloutWrapper\n",
    "\n",
    "# Define rollout manager for pendulum env\n",
    "manager = RolloutWrapper(model.apply, env_name=\"Pendulum-v1\")\n",
    "\n",
    "# Simple single episode rollout for policy\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.single_rollout(rng, policy_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple rollouts for same network (different rng, e.g. eval)\n",
    "rng_batch = jax.random.split(rng, 10)\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.batch_rollout(\n",
    "    rng_batch, policy_params\n",
    ")\n",
    "\n",
    "# Multiple rollouts for different networks + rng (e.g. for ES)\n",
    "batch_params = jax.tree_map(  # Stack parameters or use different\n",
    "    lambda x: jnp.tile(x, (5, 1)).reshape(5, *x.shape), policy_params\n",
    ")\n",
    "obs, action, reward, next_obs, done, cum_ret = manager.population_rollout(\n",
    "    rng_batch, batch_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Episode Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/jax/_src/tree_util.py:188: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.\n",
      "  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '\n",
      "WARNING:matplotlib.animation:MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gymnax.visualize import Visualizer\n",
    "\n",
    "state_seq, reward_seq = [], []\n",
    "rng, rng_reset = jax.random.split(rng)\n",
    "obs, env_state = env.reset(rng_reset, env_params)\n",
    "t_counter = 0\n",
    "while True:\n",
    "    state_seq.append(env_state)\n",
    "    rng, rng_act, rng_step = jax.random.split(rng, 3)\n",
    "    action = env.action_space(env_params).sample(rng_act)\n",
    "    next_obs, next_env_state, reward, done, info = env.step(\n",
    "        rng_step, env_state, action, env_params\n",
    "    )\n",
    "    reward_seq.append(reward)\n",
    "    t_counter += 1\n",
    "    if done or t_counter >= 50:\n",
    "        break\n",
    "    else:\n",
    "        obs = next_obs\n",
    "        env_state = next_env_state\n",
    "\n",
    "cum_rewards = jnp.cumsum(jnp.array(reward_seq))\n",
    "vis = Visualizer(env, env_params, state_seq, cum_rewards)\n",
    "vis.animate(f\"../docs/anim.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../docs/anim.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='../docs/anim.gif')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-toolbox",
   "language": "python",
   "name": "mle-toolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
