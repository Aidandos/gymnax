{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_speed': 8, 'max_torque': 2.0, 'dt': 0.05, 'g': 10.0, 'm': 1.0, 'l': 1.0, 'max_steps_in_episode': 200}\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "from flax import linen as nn\n",
    "\n",
    "import gymnax\n",
    "from gymnax.rollouts import DeterministicRollouts\n",
    "\n",
    "# 2D State Space, 3D Obs Space, 1D Action Space [Continuous - Torque]\n",
    "rng, reset, step, env_params = gymnax.make(\"Pendulum-v0\")\n",
    "print(env_params)\n",
    "\n",
    "parallel_episodes = 10\n",
    "rng, rng_net, rng_episode = jax.random.split(rng, 3)\n",
    "rng_batch = jax.random.split(rng, parallel_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Plain JAX MLP Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_policy_mlp(rng_input, sizes, scale=1e-2):\n",
    "    \"\"\" Initialize the weights of all layers of a relu + linear layer \"\"\"\n",
    "    # Initialize a single layer with Gaussian weights - helper function\n",
    "    def initialize_layer(m, n, key, scale):\n",
    "        w_key, b_key = jax.random.split(key)\n",
    "        return (scale * jax.random.normal(w_key, (n, m)),\n",
    "                scale * jax.random.normal(b_key, (n,)))\n",
    "\n",
    "    keys = jax.random.split(rng_input, len(sizes)+1)\n",
    "    W1, b1 = initialize_layer(sizes[0], sizes[1],\n",
    "                              keys[0], scale)\n",
    "    W2, b2 = initialize_layer(sizes[1], sizes[2],\n",
    "                              keys[1], scale)\n",
    "    params = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return params\n",
    "\n",
    "\n",
    "def PolicyJAX(params, obs):\n",
    "    \"\"\" Compute forward pass and return action from deterministic policy \"\"\"\n",
    "    def relu_layer(W, b, x):\n",
    "        \"\"\" Simple ReLu layer for single sample \"\"\"\n",
    "        return jnp.maximum(0, (jnp.dot(W, x) + b))\n",
    "    # Simple single hidden layer MLP: Obs -> Hidden -> Action\n",
    "    activations = relu_layer(params[\"W1\"], params[\"b1\"], obs)\n",
    "    mean_policy = jnp.dot(params[\"W2\"], activations) + params[\"b2\"]\n",
    "    return mean_policy\n",
    "\n",
    "policy_params = init_policy_mlp(rng_net, sizes=[3, 16, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DeterministicRollouts(PolicyJAX, step, reset, env_params)\n",
    "collector.init_collector(policy_params)\n",
    "trace, reward = collector.episode_rollout(rng_episode)\n",
    "traces, rewards = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit traces, rewards = collector.episode_rollout(rng_episode)\n",
    "%timeit trace, reward = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haiku MLP Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_fct(x):\n",
    "    \"\"\" Standard MLP policy network.\"\"\"\n",
    "    mlp = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(16), jax.nn.relu,\n",
    "      hk.Linear(1),\n",
    "    ])\n",
    "    return mlp(x)\n",
    "\n",
    "\n",
    "PolicyHaiku = hk.without_apply_rng(hk.transform(policy_fct))\n",
    "obs, state = reset(rng_net, env_params)\n",
    "policy_params = PolicyHaiku.init(rng_net, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DeterministicRollouts(PolicyHaiku.apply, step, reset, env_params)\n",
    "collector.init_collector(policy_params)\n",
    "trace, reward = collector.episode_rollout(rng_episode)\n",
    "traces, rewards = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit traces, rewards = collector.episode_rollout(rng_episode)\n",
    "%timeit traces, rewards = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flax MLP Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyFLAX(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(16, name='fc1')(x)\n",
    "        x = nn.relu(x)\n",
    "        action = nn.Dense(1, name='fc2')(x)\n",
    "        return action\n",
    "\n",
    "obs, state = reset(rng_net, env_params)\n",
    "policy_params = PolicyFLAX().init(rng_net, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DeterministicRollouts(PolicyFLAX().apply, step, reset, env_params)\n",
    "collector.init_collector(policy_params)\n",
    "trace, reward = collector.episode_rollout(rng_episode)\n",
    "traces, rewards = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit traces, rewards = collector.episode_rollout(rng_episode)\n",
    "%timeit trace, reward = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trax MLP Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trax = True\n",
    "if run_trax:\n",
    "    # Trax import takes forever!!!\n",
    "    import trax\n",
    "    from trax import layers as tl\n",
    "\n",
    "    # Problem with Trax: Takes input differently\n",
    "    # ---- Haiku, JAX, Flax model(params, input)\n",
    "    # ---- Trax model(input, params)\n",
    "    # Need helper function that re-routes inputs\n",
    "\n",
    "    def policy_fct():\n",
    "        model = tl.Serial(\n",
    "          tl.Dense(16),\n",
    "          tl.Relu(),\n",
    "          tl.Dense(1),\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    policy = policy_fct()\n",
    "    policy_params, _ = policy.init(trax.shapes.signature(obs))\n",
    "    def PolicyTrax(params, obs):\n",
    "        \"\"\" Helper for correct mapping of policy params & input\"\"\"\n",
    "        return policy(obs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_trax:\n",
    "    collector = DeterministicRollouts(PolicyTrax, step, reset, env_params)\n",
    "    collector.init_collector(policy_params)\n",
    "    trace, reward = collector.episode_rollout(rng_episode)\n",
    "    traces, rewards = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_trax:\n",
    "    %timeit traces, rewards = collector.episode_rollout(rng_episode)\n",
    "    %timeit trace, reward = collector.batch_rollout(rng_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffer Tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnax.rollouts import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dummy step transition & store it in buffer\n",
    "rng, reset, step, env_params = gymnax.make(\"Pendulum-v0\")\n",
    "rng, key_reset, key_step = jax.random.split(rng, 3)\n",
    "obs, state = reset(key_reset, env_params)\n",
    "action = jnp.array([1])\n",
    "next_obs, next_state, reward, done, _ = step(key_step, env_params,\n",
    "                                             state, action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = 5\n",
    "# Initialize buffer with templates\n",
    "buffer = ReplayBuffer(state, obs, action, capacity)\n",
    "for i in range(10):\n",
    "    buffer.push(state, next_state, obs, next_obs, action, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument '<gymnax.rollouts.replay_buffer.ReplayBuffer object at 0x7f805f411d30>' of type <class 'gymnax.rollouts.replay_buffer.ReplayBuffer'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bf1b3ecb1647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/ma-vision/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36mf_jitted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m   \u001b[0mf_jitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpp_jitted_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ma-vision/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_flat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m       \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     out_flat = xla.xla_call(\n",
      "\u001b[0;32m~/anaconda2/envs/ma-vision/lib/python3.6/site-packages/jax/api.py\u001b[0m in \u001b[0;36m_check_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m   2199\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_valid_jaxtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Argument '{arg}' of type {type(arg)} is not a valid JAX type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m \u001b[0;31m# TODO(necula): this duplicates code in core.valid_jaxtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument '<gymnax.rollouts.replay_buffer.ReplayBuffer object at 0x7f805f411d30>' of type <class 'gymnax.rollouts.replay_buffer.ReplayBuffer'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "rng, key_sample = jax.random.split(rng)\n",
    "buffer.sample(key_sample, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play around with reshaping of updated params after vmapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trace[4][0][0])\n",
    "print(trace[4][0][1])\n",
    "print(trace[4][1])\n",
    "print(trace[4][2][0])\n",
    "print(trace[4][2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traces[4][0][0][0])\n",
    "print(traces[4][0][1][0])\n",
    "print(traces[4][1])\n",
    "print(traces[4][2][0][0])\n",
    "print(traces[4][2][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ma-vision)",
   "language": "python",
   "name": "ma-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
